# Blog Post 3: Web Scraping
In this blog post, I will show how to scrape data from web using Scrapy.<br/>The goal is to write a webscraper finding shared actors on IMDB. Then, make recommendations from the scraped data to show how web scraping can be used in practice.


## ยง1. Setup
**To set up the Scrapy, we need to import the following.**

```
from scrapy.spiders import Spider
from scrapy.http import Request
```

**Next, we create a Spider class to help fetch data.
Spider is a program that browses websites or URLs and downloads content from them. Most of the time, we need to custom Spider since all websites are built in different ways.**

```
class ImdbSpider(Spider):
    """
    A simple spider class that navigate from a movie website to its full cast. Then scrape all the works each actors have 
    worked on.

    This spider works as follows. 
    - The parse method handles the navigation to the full credit of the movie.
    - The parse_full_credits method scrapes the links of all the actor profiles, and navigate through all of them.
    - The parse_actor_page method returns a dictionary that contains all the works each actors has worked on. 
    
    The spider will then create a dictionary called results.csv in the directory.
    """

    # the name of the spider
    name = 'imdb_spider'

    # the movie page we want to navigate
    start_urls = ['https://www.imdb.com/title/tt1375666/']
```
In this blog post, I choose the movie *Inception* to demonstrate the web scraping process.

## ยง2. Parse Functions 

**In this part, I will show how to complete our custom Spider by creating some useful parse functions allowing us to navigate through URLs and retrieve data.**

**First, we write a function called parse(self,response) to navigate from the starting url to the site containing the full cast of the movie.**

```
def parse(self,response):
        """
        This function starts on a movie page, in this case the starts_urls we set. Then, it navigates to
        the Cast & Crew page. Next, it calls the parse_full_credits(self,response) to scrpat the full cast 
        of the movie.
        This method does not return anything.
        """

        # the page containing the full cast of the movie has url <movie_url>fullcredits
        next_page = response.urljoin('fullcredits')

        # if there is a cast page, use the generator and callback to call the parse_full_credits method
        if next_page:
            # call parse_full_credits once we reach next_page
            yield Request(next_page, callback = self.parse_full_credits)
```
This method works by first finding out the url of the page we are navigating to, then call the parse_full_credits (will be defined later) method once we reach our target url through generator.

**Next, we define the parse_full_credits(self, response) method to browse all the actors' profiles.**

```
def parse_full_credits(self, response):
        """
        This function starts on the full credit page. Then, it requests urls for the page of each actor listed 
        on the page (crew members excluded). Lastly, it yields the method parse_actor_page(self, response) once it 
        reaches the actor pages. 
        This method does not return anything.
        """

        # create a list of relative paths, one for each actor
        actor_pages = [a.attrib["href"] for a in response.css("td.primary_photo a")]

        if actor_pages:
            # loop through each actor pages
            for i in actor_pages:
                # the absolute path for the actor page is 'https://www.imdb.com'+ the relative path we retrieved
                actor_page = 'https://www.imdb.com'+i
                # call parse_actor_page once we reach actor_page
                yield Request(actor_page, callback = self.parse_actor_page)
```
To write this method, I first create a list comprehension that creates a list of relative paths of each actor. Then, I modify each relative path to the absolute paths, and call the parse_actor_page method (will be defined later) once we reach each absolute URL.

**Lastly, we define the parse_actor_page(self, response) that returns a dictionary containing all the works each actor has done.**

```
def parse_actor_page(self, response):
        """
        This function starts on the page of an actor. It will yield one dictionary containing all the movie or TV shows 
        the actor has worked on. The dictionary will have two key-value pairs, of the form {"actor" : actor_name, 
        "movie_or_TV_name" : movie_or_TV_name}. 
        """
        # scrape the actor name using CSS selector: it is the text in span.itemprop
        actor_name = response.css("span.itemprop::text").get()

        # scrape all the movie or TV name the actors has worked on 
        # each filmo_row division contains one work, so we loop through all the divisions
        for quote in response.css("div.filmo-row"): 
            # get the first text in the division, which is the title of the movie or TV
            movie_or_TV_name = quote.css("a::text").get()

            # yield the dictionary
            yield {
                "actor" : actor_name,
                "movie_or_TV_name": movie_or_TV_name
            }
```

I first find out the CSS selectors of the name and works of the actor, then create a dictionary that contain two key-value pairs, of the form {"actor" : actor_name, "movie_or_TV_name" : movie_or_TV_name}.

When putting command line "scrapy crawl imdb_spider -o results.csv" in the terminal, a csv file called results.csv containing the dictionary we yielded from the parse_actor_page(self, response) method will then be created in the directory.

## ยง3. Make Recommendations
**In this section, I will utilize the dictionary we yielded from part 2, and compute a sorted list with the top movies and TV shows that share actors with the movie *Inception*.**

**As usual, I import Pandas and read in data first.**

```
import pandas as pd
df = pd.read_csv("results.csv")
```

*This is the dataframe*

**Next, I use some pandas build-in functions to clean the data.**

```
# count how many shared actors have worked on to each movie or TV
df1 = df.groupby("movie_or_TV_name").count()

# the actor column now is the count of the shared actors, so we sort the column in the descending order
df1 = df1.sort_values(by=['actor'], ascending = False)

# reset index of the dataframe and change column names
df1 = df1.reset_index()
df1.columns = ['Movie or TV name', 'Number of Shared Actors']

# display the top 10 movie or TV that have the most shared actors with the movie Inception
df1.head(10)
```

*Here is the result I got in the end...*

#### That is a tutorial of my simple movie recommender algorithm! If you are interested to learn more or view the entire code, here is the link to the git repository: *https://github.com/yuhsin-huang/webScraping*.
