---
layout: post
title: # Blog Post 5 - Image Classification
---

In this blog post, I will perform image classification that classfies dogs and cats in Tensorflow.<br>
I will use *Tensorflow Datasets* to organize operations on training, validation, and test data sets. Then, by utilizing techniques such as *data augmentation*, *data preprocessing*, and *transfer learning* while modeling, I will create an image classification algorithm with over 95% accuracy score.

## ยง1. Load Packages and Obtain Data
**As usual, we import packages and acquire data first.**

```
import os
import tensorflow as tf
from tensorflow.keras import utils, layers, applications
import matplotlib.pyplot as plt
import random
```

**Here is the code to obtain our data:**

```
# location of data
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'

# download the data and extract it
path_to_zip = utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)

# construct paths
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

# parameters for datasets
BATCH_SIZE = 32
IMG_SIZE = (160, 160)

# construct train and validation datasets 
train_dataset = utils.image_dataset_from_directory(train_dir,
                                                   shuffle=True,
                                                   batch_size=BATCH_SIZE,
                                                   image_size=IMG_SIZE)

validation_dataset = utils.image_dataset_from_directory(validation_dir,
                                                        shuffle=True,
                                                        batch_size=BATCH_SIZE,
                                                        image_size=IMG_SIZE)

# construct the test dataset by taking every 5th observation out of the validation dataset
val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)
```
The above code block creates TensorFlow Datasets for training, validation, and testing. 
We utilize a keras utility function called image_dataset_from_directory to construct a Dataset. In this function, we specify where the images are located, the randomness of the data, the batch size of the data, and the image size of the data.

**Next, we read the data.**

```
AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)
```

**To better understand our dataset, we create a function that creates a two_row visualization. In the first row, it will show three random pictures of cats, and in the second row, it will show three random pictures of dogs.**

```
def visualization(ds):

  # figure size
  plt.figure(figsize=(10, 10))
  
  #retrieve one batch (32 images with labels) from the data
  for images, labels in ds.take(1):
  
    # create two lists to contain cats and dogs
    C = []
    D = []

    for i in range(len(images)):
      # cats are labeled as 0
      if labels[i] == 0:
        C.append(i)
      # dogs are labeled as 1
      else:
        D.append(i)
    
    # randomly choose 3 samples from cats and dogs
    randC = random.sample(C, k=3)
    randD = random.sample(D, k=3)

    # create a 2x3 grids
    for i in range(6):
      ax = plt.subplot(2, 3, i + 1)

      # first row
      if i <= 2:
        plt.imshow(images[C[i]].numpy().astype("uint8"))
        plt.title('Cat')
        plt.axis("off")
        
      # second row
      else:
        plt.imshow(images[D[i-3]].numpy().astype("uint8"))
        plt.title('Dog')
        plt.axis("off")

visualization(train_dataset)
```
![post5.1.png](/images/post5.1.png)

**Now we check label frequencies and guess the accuracy of the *baseline machine learning model* based on our results.**

```
# create an iterator 
labels_iterator= train_dataset.unbatch().map(lambda image, label: label).as_numpy_iterator()

# count numbers of cats and dogs
cat = 0
dog = 0

for i in labels_iterator:
    if i == 0:
      cat += 1
    else:
      dog += 1
```
After running this code block, we get that there are 1000 dog images and 1000 cat images in our dataset.
Since the *baseline machine learning model* always guesses the most frequent label, if we run this dataset under the *baseline machine learning model*, the accuracy score will then be 50%.

## ยง2. First Model
**In this section, we create our first tf.keras.Sequential model using layers such as Conv2D layers, MaxPooling2D layers, Flatten layer, Dense layer, and Dropout layer. Then we train our model and plot the history of the accuracy on both the training and validation sets.**

```
model1 = tf.keras.models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(.2)
])

# compile model
model1.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# train model
history = model1.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

The validation accuracy of model1 stabilized between **54% and 59%** during training.
This result is a bit better than the baseline machine learning model (50% accuracy).
We also observe that the training accuracy is much higher than the validation accuracy, and hence there is an overfitting issue in model1.


## ยง3. Model with Data Augmentation
**To imporve our model's accuracy, we are going to add some data augmentation layers. Data augmentation layers will include modified copies of the same image in the training set. In this way, our model will have more data to learn *invariant features* of our input images.**

1. Create a tf.keras.layers.RandomFlip() layer that randomly flip the iamge horizontally and vertically.

```
first_layer = layers.RandomFlip()

# visualize how RandomFlip works
for images, labels in train_dataset.take(1):
  plt.figure(figsize=(10, 10))
  
  # images that has been flipped once
  next = first_layer(images[0])

  for i in range(4):
    ax = plt.subplot(1, 4, i + 1)
    
    # original image
    if i == 0:
      plt.imshow(images[i].numpy().astype("uint8"))
      plt.title("Original")
      plt.axis("off")
      
    else:
      plt.imshow(next.numpy().astype("uint8"))
      plt.title(i)
      plt.axis("off")
      
      # keep flipping the image
      next = first_layer(next)
```
![post5.2.png](/images/post5.2.png)

2. Create a tf.keras.layers.RandomRotation() layer that randomly rotate the image in a specified angle range.

```
# factor specifies the rotation angle range
second_layer = layers.RandomRotation(factor=(-0.2, 0.3), fill_mode = 'reflect')

# visualize how RandomRotation works
for images, labels in train_dataset.take(1):
  plt.figure(figsize=(10, 10))
  
  # images that has been rotated once
  next = second_layer(images[0])
  
  for i in range(4):
    ax = plt.subplot(1, 4, i + 1)
    
    # original image
    if i == 0:
      plt.imshow(images[i].numpy().astype("uint8"))
      plt.title("Original")
      plt.axis("off")
      
    else:
      plt.imshow(next.numpy().astype("uint8"))
      plt.title(i)
      plt.axis("off")
      # keep rotating the image
      next = second_layer(next)
```
![post5.3.png](/images/post5.3.png)

**Add these two data augmentation layers into our model1.**
```
model2 = tf.keras.models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    first_layer,
    second_layer,
    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(.2)
])

# compile
model2.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# train
history = model2.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

The validation accuracy of model2 stabilized between **57% and 64%** during training.
This is a little better than model1. This might be due to the fact that model2 has learned the invariant features of the input images. We also do not observe the overfitting issue on model2, and therefore we can conclude that model2 has a better performance than model1.


## ยง4. Data Preprocessing
**In this section, we will add a layer that makes simple transformations to our input data. To explain in more detail, the layer will normalized the RGB values between between 0 and 1, or possibly between -1 and 1 in order to fasten the training process.**

The following code will create a preprocessing layer that handles the normalize and weight process in advance:
```
i = tf.keras.Input(shape=(160, 160, 3))
x = tf.keras.applications.mobilenet_v2.preprocess_input(i)
preprocessor = tf.keras.Model(inputs = [i], outputs = [x])
```

Then, we add this preprocessing layer to our model:
```
model3 = tf.keras.models.Sequential([
    preprocessor,
    first_layer,
    second_layer,
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((3, 3)),
    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(.2)
])

# compile
model3.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

#train
history = model3.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

The validation accuracy of model3 stabilized between **70% and 75%** during training.
There is a huge improvement comparing model3 to model1. By normalizing the RGB values and reweighting them, the model will be able to train faster and more accurately.
We also do not observe overfitting in model3, and this is because model3 is a revised version of model2, and we have resolved the overfitting issue on model2.


## ยง5. Transfer Learning
**In this section, we will access a pre-existing "base model" called MobileNetV2 to our model. MobileNetV2 is a model which others have trained already, and it performs similar task as we do. By adding this layer to our model, we do not need to build our model from scratch anymore.**

```
# download MobileNetV2
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False

i = tf.keras.Input(shape=IMG_SHAPE)
x = base_model(i, training = False)
base_model_layer = tf.keras.Model(inputs = [i], outputs = [x])


# build our final model
model4 = tf.keras.models.Sequential([
    preprocessor,
    first_layer,
    second_layer,
    base_model_layer,
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dropout(.2),
    layers.Dense(2, activation='relu')
])

# summary of our model
model4.summary()

# compile
model4.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# train
history = model4.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```


The validation accuracy of model4 stabilized between **95% and 97%** during training.
The accuracy score is very high comparing to other models we created from scratch. However, from the model summary, we see that there are over 2 million parameters in our final model, which implies how complex a model needs to be in order to reach 95% accuracy. There is no overfitting in model4, as the overfitting issue has been resolved in model2.

## ยง6. Score on Test Data
**Now we have finished building our model, let's evaluate the accuracy of our model model on the unseen test_dataset.**

```
# predict test data based on model4
test_pred = model4.predict(test_dataset.take(6)).argmax(axis = 1)

# visualize some test data
plt.figure(figsize=(10,10))
for images, labels in test_dataset.take(6):
  for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(images[i].numpy().astype("uint8"))
    
    # label correct if the model correctly classify dogs and cats
    if test_pred[i] == labels[i]:
      plt.xlabel("correct")

plt.show()
```
![post5.4.png](/images/post5.4.png)

From the result, we see that our model perfectly classifies all the 25 random images!
